{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Debugging and Optimizing Agents: A Guide to Tracing in Reasoning Engine\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/reasoning-engine/tracing_agents_in_reasoning_engine.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Freasoning-engine/tracing_agents_in_reasoning_engine.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-enterprise-logo-32px.png\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/reasoning-engine/tracing_agents_in_reasoning_engine.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/reasoning-engine/tracing_agents_in_reasoning_engine.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84f0f73a0f76"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "| Author(s) | [Kristopher Overholt](https://github.com/koverholt) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "[Reasoning Engine](https://cloud.google.com/vertex-ai/generative-ai/docs/reasoning-engine/overview) (LangChain on Vertex AI) helps you build and deploy agent-based AI applications that use LLMs and custom tools. Understanding your agent's decision-making process is essential for debugging and optimization, and [Cloud Trace](https://cloud.google.com/trace) is a great tool for exploring this tracing data to get insights.\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/github-repo/generative-ai/gemini/reasoning-engine/images/cloud-trace-agent.png\">\n",
        "\n",
        "This notebook demonstrates how to:\n",
        "\n",
        "- **Learn Key Concepts**: Learn about the fundamental building blocks of tracing.\n",
        "- **Deploy Your Agent**: Make your tracing-enabled agent available in a production-like environment on Reasoning Engine.\n",
        "- **Enable Tracing**: Enable tracing in a simple agent\n",
        "- **Examine Traces**: Use the Cloud Console and Cloud Trace SDK to access and analyze a specific trace.\n",
        "\n",
        "By the end of this notebook, you'll be able to leverage tracing to build more robust and efficient AI agents on Vertex AI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d38b3d918526"
      },
      "source": [
        "## Concepts\n",
        "\n",
        "Here are some of the key concepts and terminology related to tracing, which will be helpful to understand as we explore traces generated by an agent in Reasoning Engine:\n",
        "\n",
        "Below is an example of a trace in JSON format, showing a single span. This span represents a call to a large language model (LLM). Notice how the trace data captures important details:\n",
        "\n",
        "### Example trace\n",
        "\n",
        "```json\n",
        "{\n",
        "   \"name\": \"llm\",\n",
        "   \"context\": {\n",
        "       \"trace_id\": \"ed7b336d-e71a-46f0-a334-5f2e87cb6cfc\",\n",
        "       \"span_id\": \"ad67332a-38bd-428e-9f62-538ba2fa90d4\"\n",
        "   },\n",
        "   \"span_kind\": \"LLM\",\n",
        "   \"parent_id\": \"f89ebb7c-10f6-4bf8-8a74-57324d2556ef\",\n",
        "   \"start_time\": \"2023-09-07T12:54:47.597121-06:00\",\n",
        "   \"end_time\": \"2023-09-07T12:54:49.321811-06:00\",\n",
        "   \"status_code\": \"OK\",\n",
        "   \"status_message\": \"\",\n",
        "   \"attributes\": {\n",
        "       \"llm.input_messages\": [\n",
        "           {\n",
        "               \"message.role\": \"system\",\n",
        "               \"message.content\": \"You are an expert Q&A system that is trusted around the world.\\nAlways answer the query using the provided context information, and not prior knowledge.\\nSome rules to follow:\\n1. Never directly reference the given context in your answer.\\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\"\n",
        "           },\n",
        "           {\n",
        "               \"message.role\": \"user\",\n",
        "               \"message.content\": \"Hello?\"\n",
        "           }\n",
        "       ],\n",
        "       \"output.value\": \"assistant: Yes I am here\",\n",
        "       \"output.mime_type\": \"text/plain\"\n",
        "   },\n",
        "   \"events\": [],\n",
        "}\n",
        "```\n",
        "\n",
        "### Trace\n",
        "\n",
        "You can think of a [trace](https://opentelemetry.io/docs/concepts/signals/traces/) like a timeline of requests as they travel through your application. A trace is composed of individual spans, with the first span representing the overall request. Each span provides details about a specific operation within the request.\n",
        "\n",
        "### Span\n",
        "\n",
        "A [span](https://opentelemetry.io/docs/concepts/signals/traces/#spans) represents a single unit of work, like a function call or an interaction with an LLM. It captures information such as the operation's name, start and end times, and any relevant attributes (metadata). Spans can be nested, showing parent-child relationships between operations.\n",
        "\n",
        "### Span Attribute\n",
        "\n",
        "[Span attributes](https://opentelemetry.io/docs/concepts/signals/traces/#attributes) are key-value pairs that provide additional context about a span. For instance, an LLM span might have attributes like the model name, prompt text, and token count.\n",
        "\n",
        "### Span Kind\n",
        "\n",
        "[Span kind](https://opentelemetry.io/docs/concepts/signals/traces/#span-kind) categorizes the type of operation a span represents. Common kinds include:\n",
        "\n",
        "- `CHAIN`: Links between LLM application steps or the start of a request.\n",
        "- `LLM`: A call to a large language model.\n",
        "- `TOOL`: An interaction with an external tool (API, database, etc.).\n",
        "- `AGENT`: A reasoning block that combines LLM and tool interactions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RBz8LLbxCR"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Vertex AI SDK and other required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tFy3H3aPgx12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --user --quiet \\\n",
        "    \"google-cloud-aiplatform[langchain,reasoningengine]\" \\\n",
        "    cloudpickle==3.0.0 \\\n",
        "    pydantic==2.7.4 \\\n",
        "    google-cloud-trace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
        "\n",
        "The restart might take a minute or longer. After it's restarted, continue to the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XRvKdaPDTznN"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information and initialize Vertex AI SDK\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"mktg-dsc-prod-f0xt\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "STAGING_BUCKET = \"gs://dsc_vertex_re_staging\"  # @param {type:\"string\"}\n",
        "\n",
        "import vertexai\n",
        "\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION, staging_bucket=STAGING_BUCKET)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you're running this notebook on Google Colab, run the cell below to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user(project_id=PROJECT_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdvJRUWRNGHE"
      },
      "source": [
        "## Build and deploy an agent\n",
        "\n",
        "Let's dive into building a simple agent that utilizes tracing. This agent will use a few custom tools to demonstrate how tracing can provide insights into its workflow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c5e77496259"
      },
      "source": [
        "### Import libraries\n",
        "\n",
        "Before you start building your agent, you'll import the necessary libraries. These include the Vertex AI SDK, pandas for data analysis, and the Cloud Trace SDK for working with trace data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5a2198c40f52"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "from typing import Dict, List\n",
        "\n",
        "import pandas as pd\n",
        "from google.cloud import trace_v1 as trace\n",
        "from vertexai.preview import reasoning_engines\n",
        "from vertexai.reasoning_engines._reasoning_engines import _utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f73957911c3"
      },
      "source": [
        "### Define tools\n",
        "\n",
        "You'll define a few Python functions to act as tools for your agent. These tools will simulate actions or API calls that a real-world agent might perform. For this example, you'll create tools to classify a customer support ticket, query a knowledge base, and escalate a ticket to a human agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0e7c7732f26f"
      },
      "outputs": [],
      "source": [
        "def classify_ticket(ticket_text: str) -> str:\n",
        "    \"\"\"Classifies a support ticket into a category.\"\"\"\n",
        "    # Simulate a call to a classification model\n",
        "    categories = {\n",
        "        \"general\": \"Questions and information\",\n",
        "        \"billing\": \"Payment and invoices\",\n",
        "        \"technical\": \"API and SDK developer documentation\",\n",
        "    }\n",
        "    if \"payment\" in ticket_text:\n",
        "        category = \"billing\"\n",
        "        description = categories[category]\n",
        "    elif \"settings\" in ticket_text:\n",
        "        category = \"technical\"\n",
        "        description = categories[category]\n",
        "    else:\n",
        "        category = \"general\"\n",
        "        description = categories[category]\n",
        "\n",
        "    return f\"This ticket is in the {category} category for questions related to {description}\"\n",
        "\n",
        "\n",
        "def search_knowledge_base(category: str) -> List[Dict]:\n",
        "    \"\"\"Searches a knowledge base for relevant articles and documentation links.\"\"\"\n",
        "    # Simulate a knowledge base search\n",
        "    articles = {\n",
        "        \"general\": [\n",
        "            {\n",
        "                \"title\": \"Contacting support\",\n",
        "                \"url\": \"https://example.com/contact\",\n",
        "            }\n",
        "        ],\n",
        "        \"billing\": [\n",
        "            {\n",
        "                \"title\": \"How to update your payment information\",\n",
        "                \"url\": \"https://example.com/billing/update\",\n",
        "            },\n",
        "        ],\n",
        "        \"technical\": [\n",
        "            {\n",
        "                \"title\": \"Troubleshooting common login issues\",\n",
        "                \"url\": \"https://example.com/technical/help\",\n",
        "            },\n",
        "        ],\n",
        "    }\n",
        "    return articles.get(category, [])\n",
        "\n",
        "\n",
        "def escalate_to_human(ticket_text: str) -> str:\n",
        "    \"\"\"Initiates escalation to a human agent for outage reports.\"\"\"\n",
        "    return \"Your ticket has been escalated to a human agent. Please expect a response within 1-2 hours.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd55dbf42903"
      },
      "source": [
        "### Define agent and enable tracing\n",
        "\n",
        "Now, let's define your agent using the LangChain template in Reasoning Engine and the Vertex AI SDK. Enable tracing by setting the `enable_tracing` parameter to `True`, which allows you to capture detailed information about the agent's execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "78fb7ab21e3a"
      },
      "outputs": [],
      "source": [
        "agent = reasoning_engines.LangchainAgent(\n",
        "    model=\"gemini-1.5-pro-001\",\n",
        "    model_kwargs={\"temperature\": 0},\n",
        "    tools=[classify_ticket, search_knowledge_base, escalate_to_human],\n",
        "    enable_tracing=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d714e7d8432"
      },
      "source": [
        "### Test your agent locally (with traces!)\n",
        "\n",
        "Let's test your agent locally by sending it a query. Since you've enabled tracing, you'll be able to see how the agent processes this request and interacts with its tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "d2e9ac4ab9e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input': '\\n    Classify the following ticket into a category and give me a relevant documentation link.\\n    \\n    Support ticket text:\\n    I need to update my billing information since my payment method has expired.\\n    ',\n",
              " 'output': \"This ticket is about billing. Here's a link to our documentation about updating your payment information: https://example.com/billing/update. \\n\"}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.query(\n",
        "    input=\"\"\"\n",
        "    Classify the following ticket into a category and give me a relevant documentation link.\n",
        "    \n",
        "    Support ticket text:\n",
        "    I need to update my billing information since my payment method has expired.\n",
        "    \"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82b1fbdafe7c"
      },
      "source": [
        "### Get your first trace\n",
        "\n",
        "Before diving deeper into trace analysis, let's use the Cloud Trace SDK to retrieve a specific trace generated by your local agent. This will give you a concrete example to work with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "d4894bb6a2d1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1724930959.273690  307823 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n",
            "I0000 00:00:1724930959.294717  307823 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
          ]
        }
      ],
      "source": [
        "client = trace.TraceServiceClient()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ea72cdb247ec"
      },
      "outputs": [],
      "source": [
        "result = [\n",
        "    r\n",
        "    for r in client.list_traces(\n",
        "        request=trace.types.ListTracesRequest(\n",
        "            project_id=PROJECT_ID,\n",
        "            # Return all traces containing `labels {key: \"openinference.span.kind\" value: \"AGENT\"}`\n",
        "            filter=\"openinference.span.kind:AGENT\",\n",
        "        )\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "c56a32df5305"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "span_id: 9129889997696345964\n",
              "name: \"AgentExecutor\"\n",
              "start_time {\n",
              "  seconds: 1724929315\n",
              "  nanos: 561400832\n",
              "}\n",
              "end_time {\n",
              "  seconds: 1724929490\n",
              "  nanos: 858717952\n",
              "}\n",
              "labels {\n",
              "  key: \"output.value\"\n",
              "  value: \"```json\\n{\\\"tool_code\\\": \\\"print(default_api.get_domain(company_name=\\'LivCor\\'))\\\", \\\"tool_name\\\": \\\"get_domain\\\", \\\"tool_input\\\": {\\\"company_name\\\": \\\"LivCor\\\"}, \\\"thought\\\": \\\"I need to get the domain name for LivCor so I can look up the company details. I\\'ll use the get_d\"\n",
              "}\n",
              "labels {\n",
              "  key: \"openinference.span.kind\"\n",
              "  value: \"AGENT\"\n",
              "}\n",
              "labels {\n",
              "  key: \"input.value\"\n",
              "  value: \"You are an expert data analyst. Use the information collected from the tools to present your response.\\n\\n            You have been given access to a get_domain tool. Please use this tool to gather information about the domain if the the query references fin\"\n",
              "}\n",
              "labels {\n",
              "  key: \"g.co/agent\"\n",
              "  value: \"opentelemetry-python 1.26.0; google-cloud-trace-exporter 1.6.0\"\n",
              "}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trace_data = client.get_trace(project_id=PROJECT_ID, trace_id=result[0].trace_id).spans[\n",
        "    0\n",
        "]\n",
        "trace_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19aa87abae0a"
      },
      "source": [
        "After you deploy your agent and make remote queries in the following sections, you'll dive into the details for working with trace data in the Cloud Console or using the Python SDK for Cloud Trace."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdGcHqUv8THp"
      },
      "source": [
        "### Deploy your agent\n",
        "\n",
        "Now that you've seen how tracing works locally, let's deploy your agent to Reasoning Engine. This will allow you to send it queries in a production-like environment and observe its behavior through traces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NrTI0_1j8E7w"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using bucket your-bucket-name\n",
            "Writing to gs://your-bucket-name/reasoning_engine/reasoning_engine.pkl\n",
            "Writing to gs://your-bucket-name/reasoning_engine/requirements.txt\n",
            "Creating in-memory tarfile of extra_packages\n",
            "Writing to gs://your-bucket-name/reasoning_engine/dependencies.tar.gz\n",
            "Creating ReasoningEngine\n",
            "Create ReasoningEngine backing LRO: projects/your-project-number/locations/us-central1/reasoningEngines/3146221736555446272/operations/2750583127503011840\n",
            "ReasoningEngine created. Resource name: projects/your-project-number/locations/us-central1/reasoningEngines/3146221736555446272\n",
            "To use this ReasoningEngine in another session:\n",
            "reasoning_engine = vertexai.preview.reasoning_engines.ReasoningEngine('projects/your-project-number/locations/us-central1/reasoningEngines/3146221736555446272')\n"
          ]
        }
      ],
      "source": [
        "remote_agent = reasoning_engines.ReasoningEngine.create(\n",
        "    agent,\n",
        "    requirements=[\n",
        "        \"google-cloud-aiplatform[langchain,reasoningengine]\",\n",
        "        \"cloudpickle==3.0.0\",\n",
        "        \"pydantic==2.7.4\",\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "019c774a18fd"
      },
      "source": [
        "### Query your deployed agent\n",
        "\n",
        "With your agent deployed, you can interact with it remotely. Let's send a query and generate some trace data to explore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zZjdFQ_Z_J43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input': '\\n    Classify the following ticket into a category and route the customer accordingly:\\n    \\n    Support ticket text:\\n    I am unable to make any API calls and I need to report an outage in the system\\n    ',\n",
              " 'output': 'The ticket has been escalated to a human agent. Please expect a response within 1-2 hours. \\n'}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "remote_agent.query(\n",
        "    input=\"\"\"\n",
        "    Classify the following ticket into a category and route the customer accordingly:\n",
        "    \n",
        "    Support ticket text:\n",
        "    I am unable to make any API calls and I need to report an outage in the system\n",
        "    \"\"\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYwmTcdgIlza"
      },
      "source": [
        "## Exploring traces in the Cloud Console\n",
        "\n",
        "The Cloud Trace console provides a powerful and intuitive visual interface for exploring trace data, including visualizing, filtering, and analyzing your traces.\n",
        "\n",
        "Accessing the Trace Console:\n",
        "\n",
        "- **Project-Level View**: To see all traces for your Google Cloud project (replace `your-project-id` with your actual project ID), go to: https://console.cloud.google.com/traces/list?project=your-project-id\n",
        "\n",
        "- **Specific Trace**: If you know the unique Trace ID for a specific trace you want to examine, you can view it directly (replace your-trace-id with the actual Trace ID): https://console.cloud.google.com/traces/list?project=your-project-id&tid=your-trace-id\n",
        "\n",
        "Features to Explore in the Console:\n",
        "\n",
        "- **Trace List**: View a list of traces, sorted by start time, along with summary information (duration, number of spans).\n",
        "- **Waterfall View**: Visualize the spans within a trace as a timeline, showing the duration of each operation and their relationships.\n",
        "- **Span Details**: Click on a span to view its attributes, including the input and output data, and any custom metadata you've added.\n",
        "- **Filtering and Search**: The console provides powerful options for filtering traces by time range, service, span name, and other criteria. You can also search for specific traces using keywords or attributes.\n",
        "\n",
        "For a detailed guide to working with traces in the console, refer to the [Cloud Trace documentation on finding traces](https://cloud.google.com/trace/docs/finding-traces). Experiment with the Cloud Trace console to gain a deeper understanding of your agent's behavior and how it's executing within Reasoning Engine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "761e2e6121f6"
      },
      "source": [
        "## Working with traces using `pandas`\n",
        "\n",
        "For more programmatic analysis, you can use the pandas library to work with trace data. You'll fetch traces, convert them to DataFrames, and then use pandas' functionality to explore the trace data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "e68cf66f2b2c"
      },
      "outputs": [],
      "source": [
        "result = [\n",
        "    r\n",
        "    for r in client.list_traces(\n",
        "        request=trace.types.ListTracesRequest(\n",
        "            project_id=PROJECT_ID,\n",
        "            # Return all traces containing `labels {key: \"openinference.span.kind\" value: \"AGENT\"}`\n",
        "            filter=\"openinference.span.kind:AGENT\",\n",
        "        )\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0ee427fa9cb3"
      },
      "outputs": [],
      "source": [
        "trace_data = client.get_trace(project_id=PROJECT_ID, trace_id=result[0].trace_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "73a61c86fc7c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>spanId</th>\n",
              "      <th>name</th>\n",
              "      <th>startTime</th>\n",
              "      <th>endTime</th>\n",
              "      <th>labels</th>\n",
              "      <th>parentSpanId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9129889997696345964</td>\n",
              "      <td>AgentExecutor</td>\n",
              "      <td>2024-08-29T11:01:55.561400832Z</td>\n",
              "      <td>2024-08-29T11:04:50.858717952Z</td>\n",
              "      <td>{'g.co/agent': 'opentelemetry-python 1.26.0; g...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16981390168131386878</td>\n",
              "      <td>RunnableSequence</td>\n",
              "      <td>2024-08-29T11:01:55.584172032Z</td>\n",
              "      <td>2024-08-29T11:02:24.718503936Z</td>\n",
              "      <td>{'g.co/agent': 'opentelemetry-python 1.26.0; g...</td>\n",
              "      <td>9129889997696345964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14465681810097984101</td>\n",
              "      <td>RunnableParallel&lt;input,agent_scratchpad&gt;</td>\n",
              "      <td>2024-08-29T11:01:55.610887168Z</td>\n",
              "      <td>2024-08-29T11:01:55.784389120Z</td>\n",
              "      <td>{'g.co/agent': 'opentelemetry-python 1.26.0; g...</td>\n",
              "      <td>16981390168131386878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1139659899946443699</td>\n",
              "      <td>ChatPromptTemplate</td>\n",
              "      <td>2024-08-29T11:01:55.873931008Z</td>\n",
              "      <td>2024-08-29T11:01:55.874848Z</td>\n",
              "      <td>{'g.co/agent': 'opentelemetry-python 1.26.0; g...</td>\n",
              "      <td>16981390168131386878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6921102655131412116</td>\n",
              "      <td>get_domain</td>\n",
              "      <td>2024-08-29T11:02:24.795828224Z</td>\n",
              "      <td>2024-08-29T11:02:25.065630976Z</td>\n",
              "      <td>{'g.co/agent': 'opentelemetry-python 1.26.0; g...</td>\n",
              "      <td>9129889997696345964</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 spanId                                      name  \\\n",
              "0   9129889997696345964                             AgentExecutor   \n",
              "1  16981390168131386878                          RunnableSequence   \n",
              "2  14465681810097984101  RunnableParallel<input,agent_scratchpad>   \n",
              "3   1139659899946443699                        ChatPromptTemplate   \n",
              "4   6921102655131412116                                get_domain   \n",
              "\n",
              "                        startTime                         endTime  \\\n",
              "0  2024-08-29T11:01:55.561400832Z  2024-08-29T11:04:50.858717952Z   \n",
              "1  2024-08-29T11:01:55.584172032Z  2024-08-29T11:02:24.718503936Z   \n",
              "2  2024-08-29T11:01:55.610887168Z  2024-08-29T11:01:55.784389120Z   \n",
              "3  2024-08-29T11:01:55.873931008Z     2024-08-29T11:01:55.874848Z   \n",
              "4  2024-08-29T11:02:24.795828224Z  2024-08-29T11:02:25.065630976Z   \n",
              "\n",
              "                                              labels          parentSpanId  \n",
              "0  {'g.co/agent': 'opentelemetry-python 1.26.0; g...                   NaN  \n",
              "1  {'g.co/agent': 'opentelemetry-python 1.26.0; g...   9129889997696345964  \n",
              "2  {'g.co/agent': 'opentelemetry-python 1.26.0; g...  16981390168131386878  \n",
              "3  {'g.co/agent': 'opentelemetry-python 1.26.0; g...  16981390168131386878  \n",
              "4  {'g.co/agent': 'opentelemetry-python 1.26.0; g...   9129889997696345964  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spans = pd.DataFrame.from_records([_utils.to_dict(span) for span in trace_data.spans])\n",
        "spans.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "a5fdff97b29f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>spanId</th>\n",
              "      <th>name</th>\n",
              "      <th>startTime</th>\n",
              "      <th>endTime</th>\n",
              "      <th>labels</th>\n",
              "      <th>parentSpanId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3877859571125750842</td>\n",
              "      <td>ChatVertexAI</td>\n",
              "      <td>2024-08-27T16:59:24.089795072Z</td>\n",
              "      <td>2024-08-27T16:59:27.840190976Z</td>\n",
              "      <td>{'llm.invocation_parameters': '{\"model_name\": ...</td>\n",
              "      <td>10621815106830957606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>5570406937849240747</td>\n",
              "      <td>ChatVertexAI</td>\n",
              "      <td>2024-08-27T16:59:28.454256128Z</td>\n",
              "      <td>2024-08-27T16:59:33.128314112Z</td>\n",
              "      <td>{'llm.input_messages.1.message.role': 'assista...</td>\n",
              "      <td>10435659226710918420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>7069817728099366601</td>\n",
              "      <td>ChatVertexAI</td>\n",
              "      <td>2024-08-27T16:59:33.734412800Z</td>\n",
              "      <td>2024-08-27T16:59:36.391567104Z</td>\n",
              "      <td>{'llm.invocation_parameters': '{\"model_name\": ...</td>\n",
              "      <td>3694277093980964884</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 spanId          name                       startTime  \\\n",
              "9   3877859571125750842  ChatVertexAI  2024-08-27T16:59:24.089795072Z   \n",
              "14  5570406937849240747  ChatVertexAI  2024-08-27T16:59:28.454256128Z   \n",
              "22  7069817728099366601  ChatVertexAI  2024-08-27T16:59:33.734412800Z   \n",
              "\n",
              "                           endTime  \\\n",
              "9   2024-08-27T16:59:27.840190976Z   \n",
              "14  2024-08-27T16:59:33.128314112Z   \n",
              "22  2024-08-27T16:59:36.391567104Z   \n",
              "\n",
              "                                               labels          parentSpanId  \n",
              "9   {'llm.invocation_parameters': '{\"model_name\": ...  10621815106830957606  \n",
              "14  {'llm.input_messages.1.message.role': 'assista...  10435659226710918420  \n",
              "22  {'llm.invocation_parameters': '{\"model_name\": ...   3694277093980964884  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spans[spans[\"name\"] == \"ChatVertexAI\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "691fe8935660"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>llm.invocation_parameters</th>\n",
              "      <th>g.co/agent</th>\n",
              "      <th>metadata</th>\n",
              "      <th>output.mime_type</th>\n",
              "      <th>llm.input_messages.0.message.role</th>\n",
              "      <th>llm.token_count.total</th>\n",
              "      <th>output.value</th>\n",
              "      <th>llm.input_messages.0.message.content</th>\n",
              "      <th>llm.output_messages.0.message.function_call_arguments_json</th>\n",
              "      <th>input.mime_type</th>\n",
              "      <th>...</th>\n",
              "      <th>llm.input_messages.1.message.content</th>\n",
              "      <th>llm.input_messages.2.message.role</th>\n",
              "      <th>llm.input_messages.1.message.function_call_arguments_json</th>\n",
              "      <th>llm.input_messages.2.message.content</th>\n",
              "      <th>llm.input_messages.1.message.function_call_name</th>\n",
              "      <th>llm.input_messages.4.message.content</th>\n",
              "      <th>llm.input_messages.3.message.role</th>\n",
              "      <th>llm.input_messages.4.message.role</th>\n",
              "      <th>llm.input_messages.3.message.function_call_name</th>\n",
              "      <th>llm.input_messages.3.message.function_call_arguments_json</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>{\"model_name\": \"gemini-1.5-pro-001\", \"candidat...</td>\n",
              "      <td>opentelemetry-python 1.26.0; google-cloud-trac...</td>\n",
              "      <td>{\"ls_provider\": \"google_vertexai\", \"ls_model_n...</td>\n",
              "      <td>application/json</td>\n",
              "      <td>user</td>\n",
              "      <td>235</td>\n",
              "      <td>{\"generations\": [[{\"text\": \"I can't answer all...</td>\n",
              "      <td>The domain name for Geico? What is the account...</td>\n",
              "      <td>{\"company_name\": \"Geico\"}</td>\n",
              "      <td>application/json</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>{\"model_name\": \"gemini-1.5-pro-001\", \"candidat...</td>\n",
              "      <td>opentelemetry-python 1.26.0; google-cloud-trac...</td>\n",
              "      <td>{\"ls_provider\": \"google_vertexai\", \"ls_model_n...</td>\n",
              "      <td>application/json</td>\n",
              "      <td>user</td>\n",
              "      <td>394</td>\n",
              "      <td>{\"generations\": [[{\"text\": \"\", \"generation_inf...</td>\n",
              "      <td>The domain name for Geico? What is the account...</td>\n",
              "      <td>{\"domain\": \"geico.com\"}</td>\n",
              "      <td>application/json</td>\n",
              "      <td>...</td>\n",
              "      <td>I can't answer all of your questions. The avai...</td>\n",
              "      <td>tool</td>\n",
              "      <td>{\"company_name\": \"Geico\"}</td>\n",
              "      <td>{\"company_name\": \"GEICO\", \"company_legal_name\"...</td>\n",
              "      <td>get_domain</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>{\"model_name\": \"gemini-1.5-pro-001\", \"candidat...</td>\n",
              "      <td>opentelemetry-python 1.26.0; google-cloud-trac...</td>\n",
              "      <td>{\"ls_provider\": \"google_vertexai\", \"ls_model_n...</td>\n",
              "      <td>application/json</td>\n",
              "      <td>user</td>\n",
              "      <td>483</td>\n",
              "      <td>{\"generations\": [[{\"text\": \"Unfortunately, the...</td>\n",
              "      <td>The domain name for Geico? What is the account...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>application/json</td>\n",
              "      <td>...</td>\n",
              "      <td>I can't answer all of your questions. The avai...</td>\n",
              "      <td>tool</td>\n",
              "      <td>{\"company_name\": \"Geico\"}</td>\n",
              "      <td>{\"company_name\": \"GEICO\", \"company_legal_name\"...</td>\n",
              "      <td>get_domain</td>\n",
              "      <td>{\"fault\": {\"faultstring\": \"Access Denied for c...</td>\n",
              "      <td>assistant</td>\n",
              "      <td>tool</td>\n",
              "      <td>get_company_details</td>\n",
              "      <td>{\"domain\": \"geico.com\"}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            llm.invocation_parameters  \\\n",
              "9   {\"model_name\": \"gemini-1.5-pro-001\", \"candidat...   \n",
              "14  {\"model_name\": \"gemini-1.5-pro-001\", \"candidat...   \n",
              "22  {\"model_name\": \"gemini-1.5-pro-001\", \"candidat...   \n",
              "\n",
              "                                           g.co/agent  \\\n",
              "9   opentelemetry-python 1.26.0; google-cloud-trac...   \n",
              "14  opentelemetry-python 1.26.0; google-cloud-trac...   \n",
              "22  opentelemetry-python 1.26.0; google-cloud-trac...   \n",
              "\n",
              "                                             metadata  output.mime_type  \\\n",
              "9   {\"ls_provider\": \"google_vertexai\", \"ls_model_n...  application/json   \n",
              "14  {\"ls_provider\": \"google_vertexai\", \"ls_model_n...  application/json   \n",
              "22  {\"ls_provider\": \"google_vertexai\", \"ls_model_n...  application/json   \n",
              "\n",
              "   llm.input_messages.0.message.role llm.token_count.total  \\\n",
              "9                               user                   235   \n",
              "14                              user                   394   \n",
              "22                              user                   483   \n",
              "\n",
              "                                         output.value  \\\n",
              "9   {\"generations\": [[{\"text\": \"I can't answer all...   \n",
              "14  {\"generations\": [[{\"text\": \"\", \"generation_inf...   \n",
              "22  {\"generations\": [[{\"text\": \"Unfortunately, the...   \n",
              "\n",
              "                 llm.input_messages.0.message.content  \\\n",
              "9   The domain name for Geico? What is the account...   \n",
              "14  The domain name for Geico? What is the account...   \n",
              "22  The domain name for Geico? What is the account...   \n",
              "\n",
              "   llm.output_messages.0.message.function_call_arguments_json  \\\n",
              "9                           {\"company_name\": \"Geico\"}           \n",
              "14                            {\"domain\": \"geico.com\"}           \n",
              "22                                                NaN           \n",
              "\n",
              "     input.mime_type  ...               llm.input_messages.1.message.content  \\\n",
              "9   application/json  ...                                                NaN   \n",
              "14  application/json  ...  I can't answer all of your questions. The avai...   \n",
              "22  application/json  ...  I can't answer all of your questions. The avai...   \n",
              "\n",
              "   llm.input_messages.2.message.role  \\\n",
              "9                                NaN   \n",
              "14                              tool   \n",
              "22                              tool   \n",
              "\n",
              "   llm.input_messages.1.message.function_call_arguments_json  \\\n",
              "9                                                 NaN          \n",
              "14                          {\"company_name\": \"Geico\"}          \n",
              "22                          {\"company_name\": \"Geico\"}          \n",
              "\n",
              "                 llm.input_messages.2.message.content  \\\n",
              "9                                                 NaN   \n",
              "14  {\"company_name\": \"GEICO\", \"company_legal_name\"...   \n",
              "22  {\"company_name\": \"GEICO\", \"company_legal_name\"...   \n",
              "\n",
              "   llm.input_messages.1.message.function_call_name  \\\n",
              "9                                              NaN   \n",
              "14                                      get_domain   \n",
              "22                                      get_domain   \n",
              "\n",
              "                 llm.input_messages.4.message.content  \\\n",
              "9                                                 NaN   \n",
              "14                                                NaN   \n",
              "22  {\"fault\": {\"faultstring\": \"Access Denied for c...   \n",
              "\n",
              "   llm.input_messages.3.message.role llm.input_messages.4.message.role  \\\n",
              "9                                NaN                               NaN   \n",
              "14                               NaN                               NaN   \n",
              "22                         assistant                              tool   \n",
              "\n",
              "   llm.input_messages.3.message.function_call_name  \\\n",
              "9                                              NaN   \n",
              "14                                             NaN   \n",
              "22                             get_company_details   \n",
              "\n",
              "   llm.input_messages.3.message.function_call_arguments_json  \n",
              "9                                                 NaN         \n",
              "14                                                NaN         \n",
              "22                            {\"domain\": \"geico.com\"}         \n",
              "\n",
              "[3 rows x 30 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spans[spans[\"name\"] == \"ChatVertexAI\"].labels.apply(pd.Series)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "450a154ab035"
      },
      "source": [
        "## Exploring traces with the Python SDK for Cloud Trace\n",
        "\n",
        "The Cloud Trace Python SDK provides even more flexibility for working with trace data. We'll use it to demonstrate how to filter traces by date, time, labels, and view types."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1e6ec298a2e"
      },
      "source": [
        "**Filter by date and time**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7593b0dd5ab1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "project_id: \"mktg-dsc-prod-f0xt\"\n",
            "trace_id: \"0a004c629c93fab3c4c508bb5b051ba9\"\n",
            "\n",
            "project_id: \"mktg-dsc-prod-f0xt\"\n",
            "trace_id: \"2dd94adf2d7bd3af34bdf6665cfa2d73\"\n",
            "\n",
            "project_id: \"mktg-dsc-prod-f0xt\"\n",
            "trace_id: \"351780f97adead64af9395cc610e8922\"\n",
            "\n",
            "project_id: \"mktg-dsc-prod-f0xt\"\n",
            "trace_id: \"528bbfb31ebee09f81e66746a8b236b5\"\n",
            "\n",
            "project_id: \"mktg-dsc-prod-f0xt\"\n",
            "trace_id: \"5fb58c562048888577f83f2a6a4a96d8\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Calculate the start and end times\n",
        "now = datetime.utcnow()\n",
        "yesterday = now - timedelta(hours=24)\n",
        "\n",
        "# Format the dates as ISO 8601 strings with 'Z' for UTC\n",
        "end_time = now.isoformat() + \"Z\"\n",
        "start_time = yesterday.isoformat() + \"Z\"\n",
        "\n",
        "# Request a filtered list of traces by date and time\n",
        "result = client.list_traces(\n",
        "    request=trace.types.ListTracesRequest(\n",
        "        project_id=PROJECT_ID,\n",
        "        start_time=start_time,\n",
        "        end_time=end_time,\n",
        "    )\n",
        ")\n",
        "\n",
        "for count, r in enumerate(result):\n",
        "    if count >= 5:\n",
        "        break\n",
        "    print(r)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0241dfa7e78e"
      },
      "source": [
        "**Filter by label**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "42f9490f60e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "project_id: \"mktg-dsc-prod-f0xt\"\n",
            "trace_id: \"0a004c629c93fab3c4c508bb5b051ba9\"\n",
            "\n",
            "project_id: \"mktg-dsc-prod-f0xt\"\n",
            "trace_id: \"351780f97adead64af9395cc610e8922\"\n",
            "\n",
            "project_id: \"mktg-dsc-prod-f0xt\"\n",
            "trace_id: \"528bbfb31ebee09f81e66746a8b236b5\"\n",
            "\n",
            "project_id: \"mktg-dsc-prod-f0xt\"\n",
            "trace_id: \"795a0e05f740de74cff111064f49d25c\"\n",
            "\n",
            "project_id: \"mktg-dsc-prod-f0xt\"\n",
            "trace_id: \"823c8c297f2132f088078625269d8865\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result = client.list_traces(\n",
        "    request=trace.types.ListTracesRequest(\n",
        "        project_id=PROJECT_ID,\n",
        "        # Return traces where any root span's name starts with AgentExecutor\n",
        "        filter=\"root:AgentExecutor\",\n",
        "    )\n",
        ")\n",
        "\n",
        "for count, r in enumerate(result):\n",
        "    if count >= 5:\n",
        "        break\n",
        "    print(r)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b13e8cc93b5d"
      },
      "source": [
        "**Filter by view type**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "154dfc32ae35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "project_id: \"mktg-dsc-prod-f0xt\"\n",
            "trace_id: \"1743dacf888f7a6cdd3bba78d9d6359d\"\n",
            "\n",
            "project_id: \"mktg-dsc-prod-f0xt\"\n",
            "trace_id: \"1fb0d7d60aee87be59427c0b8673870b\"\n",
            "\n",
            "project_id: \"mktg-dsc-prod-f0xt\"\n",
            "trace_id: \"261784d3e4fed07048ff9181975755e3\"\n",
            "\n",
            "project_id: \"mktg-dsc-prod-f0xt\"\n",
            "trace_id: \"69ad22d4bbfe2928ba6bef39c14cc5cf\"\n",
            "\n",
            "project_id: \"mktg-dsc-prod-f0xt\"\n",
            "trace_id: \"b9e11986887daea71a5c541dfc512059\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result = client.list_traces(\n",
        "    request=trace.types.ListTracesRequest(\n",
        "        project_id=PROJECT_ID,\n",
        "        # view=trace.types.ListTracesRequest.ViewType.ROOTSPAN,\n",
        "        view=trace.types.ListTracesRequest.ViewType.MINIMAL,\n",
        "        # view=trace.types.ListTracesRequest.ViewType.COMPLETE,\n",
        "    )\n",
        ")\n",
        "\n",
        "for count, r in enumerate(result):\n",
        "    if count >= 5:\n",
        "        break\n",
        "    print(r)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a4e033321ad"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "After you've finished experimenting, it's a good practice to clean up your cloud resources. You can delete the deployed Reasoning Engine instance to avoid any unexpected charges on your Google Cloud account."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "6327bf9c6ca9"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'remote_agent' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mremote_agent\u001b[49m\u001b[38;5;241m.\u001b[39mdelete()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'remote_agent' is not defined"
          ]
        }
      ],
      "source": [
        "remote_agent.delete()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "tracing_agents_in_reasoning_engine.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
